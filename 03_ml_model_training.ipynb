{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d9e9ff8-c45c-4c06-a4b1-bf4c5002ba4f",
   "metadata": {},
   "source": [
    "# ML Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debebae6-e96d-4959-899c-8882ed60040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f312568-8edf-428d-903b-7ed448562ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load feature-engineered dataset ---\n",
    "df = pd.read_csv(\"final_esg_dataset_labeled.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6679d2a2-8928-400a-899d-15ebb6b132f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define features and target ---\n",
    "features = [\n",
    "    'Total_ESG_Risk_Score', 'Predicted_ESG_Score', 'ESG_Risk_Exposure',\n",
    "    'ESG_Risk_Management', 'Environment_Score', 'Governance_Score',\n",
    "    'Social_Score', 'Controversy_Score'\n",
    "]\n",
    "target = 'ESG_Risk_Label'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb2dc33e-83f0-4c17-9d97-1240e4786e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Encode labels ---\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a93e1016-d2b7-4e3e-82ff-bfb847ec8b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding: {'High': 0, 'Low': 1, 'Medium': 2}\n"
     ]
    }
   ],
   "source": [
    "# Save for decoding later\n",
    "label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Label Encoding:\", label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49156f72-321f-4273-9a4f-8eed8b7d5e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Split data ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37406e3d-50d3-4f05-817d-cbc33ec329a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train Random Forest ---\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_preds = rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44e4ed88-9749-4729-a2c3-a4192ae26994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train XGBoost ---\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_preds = xgb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b6a2b94-0ce3-485f-b4fb-a31d61359ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Random Forest Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       1.00      1.00      1.00        30\n",
      "         Low       1.00      1.00      1.00        56\n",
      "      Medium       1.00      1.00      1.00        95\n",
      "\n",
      "    accuracy                           1.00       181\n",
      "   macro avg       1.00      1.00      1.00       181\n",
      "weighted avg       1.00      1.00      1.00       181\n",
      "\n",
      "Confusion Matrix:\n",
      " [[30  0  0]\n",
      " [ 0 56  0]\n",
      " [ 0  0 95]]\n",
      "\n",
      "üîç XGBoost Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       1.00      1.00      1.00        30\n",
      "         Low       1.00      1.00      1.00        56\n",
      "      Medium       1.00      1.00      1.00        95\n",
      "\n",
      "    accuracy                           1.00       181\n",
      "   macro avg       1.00      1.00      1.00       181\n",
      "weighted avg       1.00      1.00      1.00       181\n",
      "\n",
      "Confusion Matrix:\n",
      " [[30  0  0]\n",
      " [ 0 56  0]\n",
      " [ 0  0 95]]\n"
     ]
    }
   ],
   "source": [
    "# --- Evaluation ---\n",
    "print(\"üîç Random Forest Results:\")\n",
    "print(classification_report(y_test, rf_preds, target_names=le.classes_))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, rf_preds))\n",
    "\n",
    "print(\"\\nüîç XGBoost Results:\")\n",
    "print(classification_report(y_test, xgb_preds, target_names=le.classes_))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, xgb_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f58f18b4-3e3f-4a62-8332-5d195c5bfb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved Random Forest model and label encoder for Streamlit app.\n"
     ]
    }
   ],
   "source": [
    "# --- Save the best model\n",
    "import joblib\n",
    "joblib.dump(rf, \"rf_esg_model.pkl\")\n",
    "joblib.dump(le, \"label_encoder.pkl\")\n",
    "print(\"‚úÖ Saved Random Forest model and label encoder for Streamlit app.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d135f3dc-61e6-4d8c-a0fd-ac4a7dd9e3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Categorical columns encoded and saved.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"final_esg_dataset_labeled.csv\")\n",
    "\n",
    "# Initialize encoders\n",
    "sector_encoder = LabelEncoder()\n",
    "industry_encoder = LabelEncoder()\n",
    "controversy_level_encoder = LabelEncoder()\n",
    "\n",
    "# Encode categorical features (only if not already encoded)\n",
    "if \"Sector_encoded\" not in df.columns:\n",
    "    df[\"Sector_encoded\"] = sector_encoder.fit_transform(df[\"Sector\"])\n",
    "if \"Industry_encoded\" not in df.columns:\n",
    "    df[\"Industry_encoded\"] = industry_encoder.fit_transform(df[\"Industry\"])\n",
    "if \"Controversy_Level_encoded\" not in df.columns:\n",
    "    df[\"Controversy_Level_encoded\"] = controversy_level_encoder.fit_transform(df[\"Controversy_Level\"])\n",
    "\n",
    "# Save encoded dataset\n",
    "df.to_csv(\"final_esg_dataset_labeled.csv\", index=False)\n",
    "\n",
    "# Optionally save the encoders if needed in Streamlit\n",
    "import joblib\n",
    "encoders = {\n",
    "    \"Sector\": sector_encoder,\n",
    "    \"Industry\": industry_encoder,\n",
    "    \"Controversy_Level\": controversy_level_encoder\n",
    "}\n",
    "joblib.dump(encoders, \"label_encoders.pkl\")\n",
    "\n",
    "print(\"‚úÖ Categorical columns encoded and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f066402-d2d6-479a-9f57-374b370310eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Symbol', 'Company Name', 'Sector', 'Industry', 'Description',\n",
       "       'Total_ESG_Risk_Score', 'Predicted_ESG_Score', 'ESG_Risk_Exposure',\n",
       "       'ESG_Risk_Management', 'ESG_Risk_Level', 'Environment_Score',\n",
       "       'Governance_Score', 'Social_Score', 'Controversy_Level',\n",
       "       'Controversy_Score', 'ESG_Risk_Label', 'Sector_encoded',\n",
       "       'Industry_encoded', 'Controversy_Level_encoded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3828a062-7462-4d87-872b-6ef57b568549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc93689a-da88-4a40-a102-faedd0b777d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d77e30-5691-456b-bccb-bb116eb26d15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
